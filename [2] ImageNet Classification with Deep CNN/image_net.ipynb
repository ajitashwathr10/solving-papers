{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "QPnC1E_t7JW8",
        "outputId": "ea8bdb5a-6302-406b-adb3-340316580009"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSo, this is the basic explanation of this architecture:\\n\\nArchitecture Overview:\\n    - This one has 8 layers in total: 5 convolutionals one followed by 3 fully-connected ones.\\n    - Uses ReLU activation (f(x) = max(0, x))\\n    - Input images are of 224x224x3 RGB ratio images which is center-cropped of 256x256\\n\\nKey Points:\\n    1. Convolutional Layers:\\n        - Layer 1: 96 kernels of size 11x11x3, stride 4\\n        - Layer 2: 256 kernels of size 5x5x48\\n        - Layer 3: 384 kernels of size 3x3x256\\n        - Layer 4: 384 kernels of size 3x3x192\\n        - Layer 5: 256 kernels of size 3x3x192\\n        \\n    2. Fully Connected:\\n        - First two fully-connected: 4096 neurons each\\n        - Final layer is 1000-way softmax\\n        \\n    3. GPU Implementation:\\n        - Used 2 GPUs\\n        - Communicate only at certain layers\\n        - Handles half of the kernels\\n        \\n    4. Local Response Normalization:\\n        - Formula provides in paper:\\n            - k = 2  - n = 5\\n            - alpha = 10^ - 4\\n            - beta = 0.75\\n            \\n    5. Overlapping Pooling:\\n        - Stride (s) = 2\\n        - Filter Size (z) = 3\\n        - Max pooling follows both response-normalization layers and fifth layer\\n\\nTraining Details:\\n    1. Optimization:\\n        - Stochastic gradient descent\\n        - Batch size: 128\\n        - Momentum: 0.9\\n        - Weight Decay: 0.0005\\n        - Initial alpha: 0.01 \\n\\n    2. Initialization:\\n        - Weights: Gaussian Distribution\\n        - Bias Values\\n            - 1 for layers 2, 4, 5 and fully connected layers\\n            - 0 for rest of the layers\\n\\n    3. Dropout:\\n        - Applied to first two fully-connected\\n        - Dropout probability: 0.5\\n\\n    4. Data Augmentation:\\n        - Random crops of 224x224 from 256x256\\n        - Horizontal reflections\\n        - PCA color augmentation\\n        - 10-crop evaluation at test time\\n\\nTraining Time and Hardware:\\n    - 5-6 days on two NVIDIA GTX 580 3GB GPUs\\n    - ~90 epochs through 1.2 million training images\\n\\n    - Achieved top-5 error rates of:\\n        - 17.0% on ILSVRC-2010\\n        - 15.3% on ILSVRC-2012 \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "So, this is the basic explanation of this architecture:\n",
        "\n",
        "Architecture Overview:\n",
        "    - This one has 8 layers in total: 5 convolutionals one followed by 3 fully-connected ones.\n",
        "    - Uses ReLU activation (f(x) = max(0, x))\n",
        "    - Input images are of 224x224x3 RGB ratio images which is center-cropped of 256x256\n",
        "\n",
        "Key Points:\n",
        "    1. Convolutional Layers:\n",
        "        - Layer 1: 96 kernels of size 11x11x3, stride 4\n",
        "        - Layer 2: 256 kernels of size 5x5x48\n",
        "        - Layer 3: 384 kernels of size 3x3x256\n",
        "        - Layer 4: 384 kernels of size 3x3x192\n",
        "        - Layer 5: 256 kernels of size 3x3x192\n",
        "\n",
        "    2. Fully Connected:\n",
        "        - First two fully-connected: 4096 neurons each\n",
        "        - Final layer is 1000-way softmax\n",
        "\n",
        "    3. GPU Implementation:\n",
        "        - Used 2 GPUs\n",
        "        - Communicate only at certain layers\n",
        "        - Handles half of the kernels\n",
        "\n",
        "    4. Local Response Normalization:\n",
        "        - Formula provides in paper:\n",
        "            - k = 2  - n = 5\n",
        "            - alpha = 10^ - 4\n",
        "            - beta = 0.75\n",
        "\n",
        "    5. Overlapping Pooling:\n",
        "        - Stride (s) = 2\n",
        "        - Filter Size (z) = 3\n",
        "        - Max pooling follows both response-normalization layers and fifth layer\n",
        "\n",
        "Training Details:\n",
        "    1. Optimization:\n",
        "        - Stochastic gradient descent\n",
        "        - Batch size: 128\n",
        "        - Momentum: 0.9\n",
        "        - Weight Decay: 0.0005\n",
        "        - Initial alpha: 0.01\n",
        "\n",
        "    2. Initialization:\n",
        "        - Weights: Gaussian Distribution\n",
        "        - Bias Values\n",
        "            - 1 for layers 2, 4, 5 and fully connected layers\n",
        "            - 0 for rest of the layers\n",
        "\n",
        "    3. Dropout:\n",
        "        - Applied to first two fully-connected\n",
        "        - Dropout probability: 0.5\n",
        "\n",
        "    4. Data Augmentation:\n",
        "        - Random crops of 224x224 from 256x256\n",
        "        - Horizontal reflections\n",
        "        - PCA color augmentation\n",
        "        - 10-crop evaluation at test time\n",
        "\n",
        "Training Time and Hardware:\n",
        "    - 5-6 days on two NVIDIA GTX 580 3GB GPUs\n",
        "    - ~90 epochs through 1.2 million training images\n",
        "\n",
        "    - Achieved top-5 error rates of:\n",
        "        - 17.0% on ILSVRC-2010\n",
        "        - 15.3% on ILSVRC-2012\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Implementation:\n",
        "\n",
        "1. Complete architecture:\n",
        "    - 5 convolutional layers with specified parameters\n",
        "    - 3 fully connected layers\n",
        "    - Which totals the 8 layers\n",
        "    - Local Response Normalization\n",
        "    - ReLU activations\n",
        "    - Max pooling layers\n",
        "    - Dropout\n",
        "\n",
        "2. Training Utilites:\n",
        "    - SGD optimizer\n",
        "    - Weight initialization\n",
        "    - Random crops, Flips, Color Jittering - Data Augmentation\n",
        "    - Training and validation loops\n",
        "\n",
        "3. Key hyperparameters:\n",
        "    - Batch size: 128\n",
        "    - Learning rate: 0.01\n",
        "    - Momentum: 0.9\n",
        "    - Weight Decay: 0.0005\n",
        "    - Dropout rate: 0.5\n",
        "\n",
        "\n",
        "Note: I don't have any specialized GPUs to perform this implementation on full extent\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "plkLMqX07N9J",
        "outputId": "32311d3a-f62f-4ac5-ed73-b4f0c6fde57b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nImplementation:\\n\\n1. Complete architecture:\\n    - 5 convolutional layers with specified parameters\\n    - 3 fully connected layers \\n    - Which totals the 8 layers\\n    - Local Response Normalization\\n    - ReLU activations\\n    - Max pooling layers\\n    - Dropout\\n\\n2. Training Utilites:\\n    - SGD optimizer \\n    - Weight initialization\\n    - Random crops, Flips, Color Jittering - Data Augmentation\\n    - Training and validation loops\\n\\n3. Key hyperparameters:\\n    - Batch size: 128\\n    - Learning rate: 0.01\\n    - Momentum: 0.9\\n    - Weight Decay: 0.0005\\n    - Dropout rate: 0.5\\n\\n\\nNote: I don't have any specialized GPUs to perform this implementation on full extent\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KnH93Rcc7Tgp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageNet(nn.Module):\n",
        "    def __init__(self, num_classes = 1000):\n",
        "        super(ImageNet, self).__init__()\n",
        "\n",
        "      # First Convolutional Layer\n",
        "      # Input: 224x224x3, Output: 55x55x96\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size = 11, stride = 4, padding = 2),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k = 2),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        )\n",
        "\n",
        "        # Second Convolutional Layer\n",
        "        # Output: 27x27x256\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size = 5, padding = 2),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.LocalResponseNorm(size = 5, alpha = 0.0001, beta = 0.75, k = 2),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        )\n",
        "\n",
        "        # Third Convolutional Layer\n",
        "        # Output: 13x13x384\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size = 5, padding = 2),\n",
        "            nn.ReLU(inplace = True),\n",
        "        )\n",
        "\n",
        "        # Fourth Convolutional Layer\n",
        "        # Output: 13x13x384\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        )\n",
        "\n",
        "        # Fifth Convolutional Layer\n",
        "        # Output: 13x13x256\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size = 3, padding = 1),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2)\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(p = 0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "        # Initialize Weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 1)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "                nn.init.constant_(m.bias, 1)"
      ],
      "metadata": {
        "id": "1W-J0wHe7WRg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageNetTrainer:\n",
        "  def __init__(self, model, num_epochs = 90, batch_size = 128, learning_rate = 0.01,\n",
        "               momentum = 0.9, weight_decay = 0.0005):\n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.model = model.to(self.device)\n",
        "    self.num_epochs = num_epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr = learning_rate,\n",
        "        momentum = momentum,\n",
        "        weight_decay = weight_decay\n",
        "    )\n",
        "\n",
        "    self.train_transformer = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness = 0.1, contrast = 0.1, saturation = 0.1, hue = 0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean = [0.485, 0.456, 0.406],\n",
        "            std = [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    self.val_transfrom = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean = [0.485, 0.456, 0.406],\n",
        "            std = [0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "def train_epoch(self, train_loader):\n",
        "  self.model.train()\n",
        "  running_loss = 0.0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(self.device)\n",
        "    labels = labels.to(self.device)\n",
        "\n",
        "    self.optimizer.zero_grad()\n",
        "    outputs = self.model(images)\n",
        "    loss = self.criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  return running_loss / len(train_loader)\n",
        "\n",
        "def validate(self, val_loader):\n",
        "  self.model.eval()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "      images = images.to(self.device)\n",
        "      labels = labels.to(self.device)\n",
        "      outputs = self.model(images)\n",
        "      loss = self.criterion(outputs, labels)\n",
        "      running_loss += loss.item()\n",
        "      _, predicted = outputs.max(1)\n",
        "      total += labels.size()\n",
        "      correct += predicted.eq(labels).sum().item()\n",
        "  accuracy = 100.0 * correct / total\n",
        "  return running_loss / len(val_loader), accuracy"
      ],
      "metadata": {
        "id": "bUanh-2Z7kpx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  model = ImageNet(num_classes = 1000)\n",
        "  trainer = ImageNetTrainer(model)\n",
        "  train_dataset =\n",
        "  train_loader = DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size = trainer.batch_size,\n",
        "      shuffle = True,\n",
        "      num_workers = 4\n",
        "  )\n",
        "  for epoch in range(trainer.num_epochs):\n",
        "        train_loss = trainer.train_epoch(train_loader)\n",
        "        val_loss, val_accuracy = trainer.validate(val_loader)\n",
        "\n",
        "        print(f'Epoch [{epoch+1} / {trainer.num_epochs}]')\n",
        "        print(f'Training Loss: {train_loss:.4f}')\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "        print(f'Validation Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "lbYwMv7E-RSG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "Vna4n04-_gtm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nwnONyl_jga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}